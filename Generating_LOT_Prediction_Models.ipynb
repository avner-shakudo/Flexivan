{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pyfiglet\n",
    "\n",
    "from colorama import Fore, Style\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Flexivan_Prediction_Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 Filenames were found\n",
      "['Latest_Test_2025-02-16.csv', 'Latest_Test_2025-02-23.csv', 'Latest_Test_2025-02-25.csv', 'Latest_Test_2025-03-02.csv', 'Latest_Test_2025-03-03.csv', 'Latest_Test_2025-03-04.csv', 'Latest_Test_2025-03-05.csv', 'Latest_Test_2025-03-06.csv', 'Latest_Test_2025-03-07.csv', 'Latest_Test_2025-03-08.csv', 'Latest_Test_2025-03-09.csv', 'Latest_Test_2025-03-10.csv', 'Latest_Test_2025-03-11.csv', 'Latest_Test_2025-03-12.csv', 'Latest_Test_2025-03-13.csv', 'Latest_Test_2025-03-14.csv', 'Latest_Test_2025-03-15.csv', 'Latest_Test_2025-03-16.csv', 'Latest_Test_2025-03-17.csv', 'Latest_Test_2025-03-18.csv', 'Latest_Test_2025-03-19.csv', 'Latest_Test_2025-03-20.csv', 'Latest_Test_2025-03-21.csv', 'Latest_Test_2025-03-22.csv', 'Latest_Test_2025-03-23.csv', 'Latest_Test_2025-03-24.csv', 'Latest_Test_2025-03-25.csv', 'Latest_Test_2025-03-26.csv', 'Latest_Test_2025-03-27.csv', 'Latest_Test_2025-03-28.csv', 'Latest_Test_2025-03-29.csv', 'Latest_Test_2025-03-30.csv', 'Latest_Test_2025-03-31.csv', 'Latest_Test_2025-04-01.csv', 'Latest_Test_2025-04-02.csv', 'Latest_Test_2025-04-03.csv', 'Latest_Test_2025-04-04.csv', 'Latest_Test_2025-04-05.csv', 'Latest_Test_2025-04-06.csv', 'Latest_Test_2025-04-07.csv', 'Latest_Test_2025-04-08.csv', 'Latest_Test_2025-04-09.csv', 'Latest_Test_2025-04-10.csv', 'Latest_Test_2025-04-11.csv', 'Latest_Test_2025-04-12.csv', 'Latest_Test_2025-04-13.csv', 'Latest_Test_2025-04-14.csv', 'Latest_Test_2025-04-15.csv', 'Latest_Test_2025-04-16.csv', 'Latest_Test_2025-04-17.csv', 'Latest_Test_2025-04-18.csv', 'Latest_Test_2025-04-19.csv', 'Latest_Test_2025-04-20.csv', 'Latest_Test_2025-04-21.csv', 'Latest_Test_2025-04-22.csv', 'Latest_Test_2025-04-23.csv', 'Latest_Test_2025-04-24.csv', 'Latest_Test_2025-04-25.csv', 'Latest_Test_2025-04-26.csv', 'Latest_Test_2025-04-27.csv', 'Latest_Test_2025-04-28.csv', 'Latest_Test_2025-04-29.csv', 'Latest_Test_2025-04-30.csv', 'Latest_Test_2025-05-01.csv', 'Latest_Test_2025-05-02.csv', 'Latest_Test_2025-05-03.csv', 'Latest_Test_2025-05-04.csv', 'Latest_Test_2025-05-05.csv', 'Latest_Test_2025-05-06.csv', 'Latest_Test_2025-05-07.csv', 'Latest_Test_2025-05-08.csv', 'Latest_Test_2025-05-09.csv', 'Latest_Test_2025-05-10.csv', 'Latest_Test_2025-05-11.csv', 'Latest_Test_2025-05-12.csv', 'Latest_Test_2025-05-13.csv', 'Latest_Test_2025-05-14.csv', 'Latest_Test_2025-05-15.csv', 'Latest_Test_2025-05-16.csv', 'Latest_Test_2025-05-17.csv', 'Latest_Test_2025-05-18.csv', 'Latest_Test_2025-05-19.csv', 'Latest_Test_2025-05-20.csv', 'Latest_Test_2025-05-21.csv', 'Latest_Test_2025-05-22.csv', 'Latest_Test_2025-05-23.csv', 'Latest_Test_2025-05-24.csv', 'Latest_Test_2025-05-25.csv', 'Latest_Test_2025-05-26.csv', 'Latest_Test_2025-05-27.csv', 'Latest_Test_2025-05-28.csv', 'Latest_Test_2025-05-29.csv', 'Latest_Test_2025-05-30.csv', 'Latest_Test_2025-05-31.csv', 'Latest_Test_2025-06-01.csv', 'Latest_Test_2025-06-02.csv', 'Latest_Test_2025-06-03.csv', 'Latest_Test_2025-06-04.csv', 'Latest_Test_2025-06-05.csv', 'Latest_Test_2025-06-06.csv', 'Latest_Test_2025-06-07.csv', 'Latest_Test_2025-06-08.csv', 'Latest_Test_2025-06-09.csv', 'Latest_Test_2025-06-10.csv', 'Latest_Test_2025-06-11.csv', 'Latest_Test_2025-06-12.csv', 'Latest_Test_2025-06-13.csv', 'Latest_Test_2025-06-14.csv', 'Latest_Test_2025-06-15.csv', 'Latest_Test_2025-06-16.csv', 'Latest_Test_2025-06-17.csv', 'Latest_Test_2025-06-18.csv', 'Latest_Test_2025-06-19.csv', 'Latest_Test_2025-06-20.csv', 'Latest_Test_2025-06-21.csv', 'Latest_Test_2025-06-22.csv', 'Latest_Test_2025-06-23.csv', 'Latest_Test_2025-06-24.csv', 'Latest_Test_2025-06-25.csv', 'Latest_Test_2025-06-26.csv', 'Latest_Test_2025-06-27.csv', 'Latest_Test_2025-06-28.csv', 'Latest_Test_2025-06-29.csv', 'Latest_Test_2025-06-30.csv', 'Latest_Test_2025-07-01.csv', 'Latest_Test_2025-07-02.csv', 'Latest_Test_2025-07-03.csv', 'Latest_Test_2025-07-04.csv', 'Latest_Test_2025-07-05.csv', 'Latest_Test_2025-07-06.csv', 'Latest_Test_2025-07-07.csv', 'Latest_Test_2025-07-08.csv', 'Latest_Test_2025-07-09.csv', 'Latest_Test_2025-07-10.csv', 'Latest_Test_2025-07-11.csv', 'Latest_Test_2025-07-12.csv', 'Latest_Test_2025-07-13.csv', 'Latest_Test_2025-07-14.csv', 'Latest_Test_2025-07-15.csv', 'Latest_Test_2025-07-16.csv', 'Latest_Test_2025-07-17.csv', 'Latest_Test_2025-07-18.csv', 'Latest_Test_2025-07-19.csv', 'Latest_Test_2025-07-20.csv', 'Latest_Test_2025-07-21.csv', 'Latest_Test_2025-07-22.csv', 'Latest_Test_2025-07-23.csv', 'Latest_Test_2025-07-24.csv', 'Latest_Test_2025-07-25.csv', 'Latest_Test_2025-07-26.csv', 'Latest_Test_2025-07-27.csv', 'Latest_Test_2025-07-28.csv', 'Latest_Test_2025-07-29.csv', 'Latest_Test_2025-07-30.csv', 'Latest_Test_2025-07-31.csv', 'Latest_Test_2025-08-01.csv', 'Latest_Test_2025-08-02.csv', 'Latest_Test_2025-08-03.csv', 'Latest_Test_2025-08-04.csv', 'Latest_Test_2025-08-05.csv', 'Latest_Test_2025-08-06.csv', 'Latest_Test_2025-08-07.csv', 'Latest_Test_2025-08-08.csv', 'Latest_Test_2025-08-09.csv', 'Latest_Test_2025-08-10.csv', 'Latest_Test_2025-08-11.csv', 'Latest_Test_2025-08-12.csv', 'Latest_Test_2025-08-13.csv', 'Latest_Test_2025-08-14.csv', 'Latest_Test_2025-08-15.csv', 'Latest_Test_2025-08-16.csv', 'Latest_Test_2025-08-17.csv', 'Latest_Test_2025-08-18.csv', 'Latest_Test_2025-08-19.csv', 'Latest_Test_2025-08-20.csv', 'Latest_Test_2025-08-21.csv', 'Latest_Test_2025-08-22.csv', 'Latest_Test_2025-08-23.csv', 'Latest_Test_2025-08-24.csv', 'Latest_Test_2025-08-25.csv', 'Latest_Test_2025-08-26.csv', 'Latest_Test_2025-08-27.csv', 'Latest_Test_2025-08-28.csv', 'Latest_Test_2025-08-29.csv', 'Latest_Test_2025-08-30.csv', 'Latest_Test_2025-08-31.csv', 'Latest_Test_2025-09-01.csv', 'Latest_Test_2025-09-02.csv', 'Latest_Test_2025-09-03.csv', 'Latest_Test_2025-09-04.csv', 'Latest_Test_2025-09-05.csv', 'Latest_Test_2025-09-06.csv', 'Latest_Test_2025-09-07.csv', 'Latest_Test_2025-09-08.csv', 'Latest_Test_2025-09-09.csv', 'Latest_Test_2025-09-10.csv', 'Latest_Test_2025-09-11.csv', 'Latest_Test_2025-09-12.csv', 'Latest_Test_2025-09-13.csv', 'Latest_Test_2025-09-14.csv', 'Latest_Test_2025-09-15.csv', 'Latest_Test_2025-09-16.csv', 'Latest_Test_2025-09-17.csv', 'Latest_Test_2025-09-18.csv', 'Latest_Test_2025-09-19.csv', 'Latest_Test_2025-09-20.csv', 'Latest_Test_2025-09-21.csv', 'Latest_Test_2025-09-22.csv', 'Latest_Test_2025-09-23.csv', 'Latest_Test_2025-09-24.csv', 'Latest_Test_2025-09-25.csv', 'Latest_Test_2025-09-26.csv', 'Latest_Test_2025-09-27.csv', 'Latest_Test_2025-09-28.csv', 'Latest_Test_2025-09-29.csv', 'Latest_Test_2025-09-30.csv', 'Latest_Test_2025-10-01.csv', 'Latest_Test_2025-10-02.csv', 'Latest_Test_2025-10-02_OTO.csv', 'Latest_Test_2025-10-03.csv', 'Latest_Test_2025-10-04.csv', 'Latest_Test_2025-10-05.csv', 'Latest_Test_2025-10-06.csv', 'Latest_Test_2025-10-07.csv', 'Latest_Test_2025-10-08.csv', 'Latest_Test_2025-10-09.csv', 'Latest_Test_2025-10-10.csv', 'Latest_Test_2025-10-11.csv', 'Latest_Test_2025-10-12.csv', 'Latest_Test_2025-10-13.csv', 'Latest_Test_2025-10-14.csv', 'Latest_Test_2025-10-15.csv', 'Latest_Test_2025-10-16.csv', 'Latest_Test_2025-10-17.csv', 'Latest_Test_2025-10-18.csv', 'Latest_Test_2025-10-19.csv', 'Latest_Test_2025-10-20.csv', 'Latest_Test_2025-10-21.csv', 'Latest_Test_2025-10-22.csv', 'Latest_Test_2025-10-23.csv', 'Latest_Test_2025-10-24.csv', 'Latest_Test_2025-10-25.csv', 'Latest_Test_2025-10-26.csv', 'Latest_Test_2025-10-27.csv', 'Latest_Test_2025-10-28.csv', 'Latest_Test_2025-10-29.csv', 'Latest_Test_2025-10-30.csv', 'Latest_Test_2025-10-31.csv', 'Latest_Test_2025-11-01.csv', 'Latest_Test_2025-11-02.csv']\n"
     ]
    }
   ],
   "source": [
    "# Get filenames from folder\n",
    "DATA_Folder = './Daily prediction/DATA'\n",
    "\n",
    "FILENAMES = [f for f in os.listdir(DATA_Folder) if os.path.isfile(os.path.join(DATA_Folder, f))]\n",
    "selected = \"Latest_Test_\"\n",
    "selected2 = '_DETAILED'\n",
    "FILENAMES = [f for f in FILENAMES if selected in f and selected2 not in f]\n",
    "DATES = Flexivan_Prediction_Package.extract_datetimes_from_filenames(FILENAMES)\n",
    "Filenames_DF = pd.DataFrame({\n",
    "    \"Filenames\": FILENAMES,\n",
    "    \"Dates\": DATES\n",
    "})\n",
    "Filenames_DF_Sorted = Filenames_DF.sort_values(by='Dates')\n",
    "FILENAMES = list(Filenames_DF_Sorted['Filenames'])\n",
    "DATES = list(Filenames_DF_Sorted['Dates'])\n",
    "\n",
    "print(f'{len(FILENAMES)} Filenames were found')\n",
    "print(FILENAMES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ____        _ _     _ _                                    _      _           \n",
      "| __ ) _   _(_) | __| (_)_ __   __ _    _ __ ___   ___   __| | ___| |___       \n",
      "|  _ \\| | | | | |/ _` | | '_ \\ / _` |  | '_ ` _ \\ / _ \\ / _` |/ _ \\ / __|      \n",
      "| |_) | |_| | | | (_| | | | | | (_| |  | | | | | | (_) | (_| |  __/ \\__ \\_ _ _ \n",
      "|____/ \\__,_|_|_|\\__,_|_|_| |_|\\__, |  |_| |_| |_|\\___/ \\__,_|\\___|_|___(_|_|_)\n",
      "                               |___/                                           \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file:\t\u001b[33mLatest_Test_2025-02-16.csv\u001b[39m...DONE.\n",
      "Samples num:\t\u001b[33m14,112\u001b[39m (\u001b[33m (96\u001b[39m% out of original data after cleaning)\n",
      "\tLAXAIM \u001b[31m\tdoes not \u001b[39mhave a LOT prediction model -->> TRAINING...\u001b[32mDONE.\u001b[39m\n",
      "\tLAXCSN \u001b[31m\tdoes not \u001b[39mhave a LOT prediction model -->> TRAINING...\u001b[32mDONE.\u001b[39m\n",
      "\tCHIIIC \u001b[31m\tdoes not \u001b[39mhave a LOT prediction model -->> TRAINING...\u001b[32mDONE.\u001b[39m\n",
      "\tWBCT \u001b[31m\tdoes not \u001b[39mhave a LOT prediction model -->> TRAINING...\u001b[32mDONE.\u001b[39m\n",
      "\tLAXICE \u001b[31m\tdoes not \u001b[39mhave a LOT prediction model -->> TRAINING...\u001b[32mDONE.\u001b[39m\n",
      "\tSAVCMP \u001b[31m\tdoes not \u001b[39mhave a LOT prediction model -->> TRAINING...\u001b[32mDONE.\u001b[39m\n",
      "\tOAKSTE \u001b[31m\tdoes not \u001b[39mhave a LOT prediction model -->> TRAINING...\u001b[32mDONE.\u001b[39m\n",
      "\tTACTHG \u001b[31m\tdoes not \u001b[39mhave a LOT prediction model -->> TRAINING...\u001b[32mDONE.\u001b[39m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/250 [01:02<4:21:02, 62.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file:\t\u001b[33mLatest_Test_2025-02-23.csv\u001b[39m...DONE.\n",
      "Samples num:\t\u001b[33m124,988\u001b[39m (\u001b[33m (94\u001b[39m% out of original data after cleaning)\n",
      "\u001b[32m\tModel exists - \u001b[39m\tLAXAIM \u001b[31m\tdoes not \u001b[39mhave a LOT prediction model -->> TRAINING...\u001b[32mDONE.\u001b[39m\n",
      "\u001b[32m\tModel exists - \u001b[39m\tLAXCSN \u001b[31m\tdoes not \u001b[39mhave a LOT prediction model -->> TRAINING...\u001b[32mDONE.\u001b[39m\n",
      "\u001b[32m\tModel exists - \u001b[39m\tOAKSTE \u001b[31m\tdoes not \u001b[39mhave a LOT prediction model -->> TRAINING...\u001b[32mDONE.\u001b[39m\n",
      "\u001b[32m\tModel exists - \u001b[39m\tTACTHG \u001b[31m\tdoes not \u001b[39mhave a LOT prediction model -->> TRAINING...\u001b[32mDONE.\u001b[39m\n",
      "\tLAXBAC \u001b[31m\tdoes not \u001b[39mhave a LOT prediction model -->> TRAINING...\u001b[32mDONE.\u001b[39m\n",
      "\u001b[32m\tModel exists - \u001b[39m\tCHIIIC \u001b[31m\tdoes not \u001b[39mhave a LOT prediction model -->> TRAINING...\u001b[32mDONE.\u001b[39m\n",
      "\u001b[32m\tModel exists - \u001b[39m\tWBCT \u001b[31m\tdoes not \u001b[39mhave a LOT prediction model -->> TRAINING...\u001b[32mDONE.\u001b[39m\n",
      "\u001b[32m\tModel exists - \u001b[39m\tLAXICE \u001b[31m\tdoes not \u001b[39mhave a LOT prediction model -->> TRAINING...\u001b[32mDONE.\u001b[39m\n",
      "\tORFMRS \u001b[31m\tdoes not \u001b[39mhave a LOT prediction model -->> TRAINING..."
     ]
    }
   ],
   "source": [
    "LOT_Transition_Matrix = None\n",
    "lot_index = None\n",
    "Test_Ratio = .2\n",
    "LOT_MODELS = {}                         # Model per LOT\n",
    "Accuracy_THR_4_Retraining = .8\n",
    "random_state = 42\n",
    "\n",
    "Sorting_Field='CHS Pickup Date'\n",
    "Columns_2_Drop_From_Training = ['CHS ID', 'CTR Trip Id', 'CHS Return Dt', 'CHS Return LOC', 'CHS Pickup Date', 'CTR pick Dt', 'CTR Return Dt']\n",
    "Enumerated_Columns_LIST = ['CHS Pickup Loc', 'CHS Return Loc', 'CHS pickup MCO', 'CTR Trip MCO', 'O Customer', 'Customer', 'DC Loc', 'CTR Pickup Term', 'CTR Return Term', \n",
    "                           'pgkey', 'CTR Trip Loc Type Pattern', 'CTR Trip Pattern']\n",
    "\n",
    "print(pyfiglet.figlet_format(\"Building  models...\"))\n",
    "\n",
    "for filename in tqdm(FILENAMES):\n",
    "    print(f'Reading file:\\t' + Fore.YELLOW + f'{filename}' + Fore.RESET + '...', end='')\n",
    "    File_Analysis_Results_OBJ = Flexivan_Prediction_Package.File_Analysis_Reults(f'{DATA_Folder}/{filename}', Sorting_Field, Columns_2_Drop_From_Training, Enumerated_Columns_LIST)\n",
    "    \n",
    "    percentage = int(100*len(File_Analysis_Results_OBJ.DATA)/len(File_Analysis_Results_OBJ.DATA_ORIG))\n",
    "    print('Samples num:\\t' + Fore.YELLOW + f'{Flexivan_Prediction_Package.Comma_Separation_Num_String(len(File_Analysis_Results_OBJ.DATA))}' + Fore.RESET + ' (' + Fore.YELLOW + f' ({percentage}' + Fore.RESET + '% out of original data after cleaning)')\n",
    "\n",
    "    # Supplumenting (building if necessary) the models\n",
    "    PU_LOTs_Unique = list(File_Analysis_Results_OBJ.DATA_ORIG['CHS Pickup Loc'].unique())\n",
    "\n",
    "    for pu_lot in PU_LOTs_Unique:\n",
    "        DATA = File_Analysis_Results_OBJ.DATA[File_Analysis_Results_OBJ.DATA['CHS Pickup Loc']==pu_lot]\n",
    "        PU_LOT_COL = np.array(DATA['CHS Pickup Loc'])\n",
    "        DATA.drop(columns=['CHS Pickup Loc'], inplace=True)\n",
    "        \n",
    "        try:\n",
    "            MODEL = LOT_MODELS[pu_lot]\n",
    "            print(Fore.GREEN + f'\\tModel exists - ' + Fore.RESET, end='')\n",
    "\n",
    "            # Model exists for that LOT, classify the whole file\n",
    "            print(f'making predictions for {Flexivan_Prediction_Package.Comma_Separation_Num_String(len(PU_LOT_COL))} samples...', end='')\n",
    "            DATA = Flexivan_Prediction_Package.align_df_to_model(DATA, MODEL, fill_value=0)\n",
    "            y_pred = np.array(MODEL.predict(DATA))\n",
    "            \n",
    "            # Check results accuracy\n",
    "            DIFF = np.array(y_pred - PU_LOT_COL)\n",
    "            Indexes = DIFF[DIFF==0]\n",
    "            Accuracy = len(Indexes) / len(PU_LOT_COL)\n",
    "            if Accuracy<Accuracy_THR_4_Retraining:\n",
    "                print(f'\\n\\tAccuracy = ' + Fore.RED + f'{Accuracy}' + Fore.RESET)\n",
    "             \n",
    "                # Retrain if necessary\n",
    "                print('\\tRe-Training...', end='')\n",
    "                xgb_params = {'n_estimators': 100, 'random_state': random_state, 'verbosity': 0, 'num_class': len(set(PU_LOTs_Unique))}\n",
    "                model = XGBClassifier(**xgb_params)\n",
    "\n",
    "                model.fit(DATA, PU_LOT_COL)\n",
    "                LOT_MODELS[pu_lot] = model\n",
    "                print(Fore.GREEN + 'DONE.' + Fore.RESET)\n",
    "            else:\n",
    "                print(f'\\n\\tAccuracy = ' + Fore.GREEN + f'{accuracy}' + Fore.RESET)\n",
    "\n",
    "        except:\n",
    "            # Model for LOT does not exist, train from current file (whole)\n",
    "\n",
    "            print(f'\\t{pu_lot} ' + Fore.RED + '\\tdoes not ' + Fore.RESET + 'have a LOT prediction model -->> TRAINING...', end='')\n",
    "            xgb_params = {'n_estimators': 100, 'random_state': random_state, 'verbosity': 0, 'num_class': len(set(PU_LOT_COL))}\n",
    "            model = XGBClassifier(**xgb_params)\n",
    "\n",
    "            model.fit(DATA, PU_LOT_COL)\n",
    "            LOT_MODELS[pu_lot] = model\n",
    "            print(Fore.GREEN + 'DONE.' + Fore.RESET)\n",
    "\n",
    "    print('\\n\\n')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-Flex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
